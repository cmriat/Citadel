"""
ä¸‰ç›¸æœºè§†é¢‘é€å¸§å¯¹æ¯”å¯è§†åŒ–å·¥å…·ã€‚

å°† convert åçš„ä¸‰ä¸ªç›¸æœº MP4 å¹¶æ’æ‹¼æ¥ä¸ºä¸€ä¸ªåˆæˆè§†é¢‘ï¼Œæ¯å¸§å·¦ä¸Šè§’æ ‡æ³¨å¸§å·ï¼Œ
è¾“å‡ºå•ä¸ª MP4 æ–‡ä»¶ï¼Œç”¨ä»»æ„æ’­æ”¾å™¨é€å¸§æŸ¥çœ‹å³å¯éªŒè¯æ—¶é—´å¯¹é½è´¨é‡ã€‚

Usage:
    pixi run python scripts/visualize_video_sync.py /path/to/lerobot --episode 141
    pixi run python scripts/visualize_video_sync.py /path/to/lerobot --episode 141 --output /tmp/sync.mp4
    pixi run python scripts/visualize_video_sync.py /path/to/lerobot --episode 141 --fps 25

é€å¸§æŸ¥çœ‹æç¤º (æ’­æ”¾å™¨å¿«æ·é”®):
    mpv:   .  ä¸‹ä¸€å¸§    ,  ä¸Šä¸€å¸§    ç©ºæ ¼ æ’­æ”¾/æš‚åœ
    VLC:   E  ä¸‹ä¸€å¸§    Shift+â† å›é€€    ç©ºæ ¼ æ’­æ”¾/æš‚åœ
    ffplay: S  ä¸‹ä¸€å¸§    å·¦å³æ–¹å‘é”® è·³è·ƒ
"""

import argparse
from pathlib import Path
from typing import List

import av
import numpy as np


# ç›¸æœºåç§°æ˜ å°„
CAMERA_KEYS = [
    "observation.images.cam_env",
    "observation.images.cam_left_wrist",
    "observation.images.cam_right_wrist",
]
CAMERA_LABELS = ["cam_env", "cam_left_wrist", "cam_right_wrist"]

# æ ‡ç­¾æ é«˜åº¦ (åƒç´ )
LABEL_BAR_HEIGHT = 28


def decode_video(video_path: Path) -> np.ndarray:
    """å°† MP4 è§£ç ä¸º [N, H, W, 3] uint8 æ•°ç»„ã€‚"""
    container = av.open(str(video_path))
    stream = container.streams.video[0]

    frames = []
    for frame in container.decode(stream):
        img = frame.to_ndarray(format='rgb24')
        frames.append(img)

    container.close()
    return np.stack(frames, axis=0)


def _resolve_episode_dir(output_dir: Path, episode_index: int) -> Path:
    """è§£æ episode çš„å®é™…ç›®å½•ã€‚

    æ”¯æŒä¸¤ç§ç›®å½•ç»“æ„ï¼š
      ç»“æ„A (å• episode ä¸€ä¸ªç›®å½•):  output_dir/episode_NNNN/videos/chunk-000/...
      ç»“æ„B (åˆå¹¶è¾“å‡º):             output_dir/videos/chunk-000/.../episode_NNNNNN.mp4
    """
    # ç»“æ„A: output_dir ä¸‹æœ‰ episode_NNNN å­ç›®å½•
    ep_subdir = output_dir / f"episode_{episode_index:04d}"
    if not ep_subdir.exists():
        ep_subdir = output_dir / f"episode_{episode_index:06d}"
    if ep_subdir.exists() and (ep_subdir / "videos").exists():
        return ep_subdir

    # ç»“æ„B: output_dir æœ¬èº«å°±æ˜¯ LeRobot ç›®å½•
    if (output_dir / "videos").exists():
        return output_dir

    raise FileNotFoundError(
        f"æ— æ³•å®šä½ episode {episode_index} çš„è§†é¢‘ç›®å½•ã€‚\n"
        f"  å°è¯•è¿‡: {output_dir}/episode_{episode_index:04d}/videos\n"
        f"  å°è¯•è¿‡: {output_dir}/videos"
    )


def find_episode_videos(output_dir: Path, episode_index: int = 0) -> List[Path]:
    """æŸ¥æ‰¾æŒ‡å®š episode çš„ä¸‰ä¸ªç›¸æœºè§†é¢‘è·¯å¾„ã€‚"""
    ep_dir = _resolve_episode_dir(output_dir, episode_index)

    paths = []
    for cam_key in CAMERA_KEYS:
        cam_dir = ep_dir / "videos" / "chunk-000" / cam_key
        if not cam_dir.exists():
            raise FileNotFoundError(f"ç›¸æœºç›®å½•ä¸å­˜åœ¨: {cam_dir}")
        mp4s = sorted(cam_dir.glob("episode_*.mp4"))
        if not mp4s:
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {cam_dir}/episode_*.mp4")
        paths.append(mp4s[0])
    return paths


def list_available_episodes(output_dir: Path) -> List[int]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ episode ç´¢å¼•ã€‚"""
    # ç»“æ„A: output_dir ä¸‹æœ‰ episode_NNNN å­ç›®å½•
    ep_dirs = sorted(output_dir.glob("episode_*"))
    if ep_dirs and (ep_dirs[0] / "videos").exists():
        episodes = []
        for d in ep_dirs:
            if d.is_dir() and (d / "videos").exists():
                idx_str = d.name.replace("episode_", "")
                try:
                    episodes.append(int(idx_str))
                except ValueError:
                    pass
        if episodes:
            return sorted(episodes)

    # ç»“æ„B: åˆå¹¶è¾“å‡º
    video_dir = output_dir / "videos" / "chunk-000" / CAMERA_KEYS[0]
    if not video_dir.exists():
        return []
    episodes = []
    for mp4 in sorted(video_dir.glob("episode_*.mp4")):
        idx_str = mp4.stem.replace("episode_", "")
        episodes.append(int(idx_str))
    return episodes


def draw_text_on_frame(frame: np.ndarray, text: str, x: int = 4, y: int = 18,
                       color=(255, 255, 0)) -> np.ndarray:
    """åœ¨å¸§ä¸Šç»˜åˆ¶ç®€æ˜“æ–‡æœ¬ (æ— éœ€ PIL/cv2ï¼Œç”¨åƒç´ å—æ¸²æŸ“)ã€‚

    ä½¿ç”¨ç®€åŒ–çš„ 5x7 åƒç´ å­—ä½“ï¼Œä»…æ”¯æŒæ•°å­—ã€å­—æ¯å’ŒåŸºæœ¬ç¬¦å·ã€‚
    """
    # ç®€åŒ–æ–¹æ¡ˆï¼šåœ¨å·¦ä¸Šè§’ç”»ä¸€ä¸ªåŠé€æ˜èƒŒæ™¯ + ç”¨ numpy å®ç°ç®€å•å­—ç¬¦
    # ä¸ºäº†é¿å…ä¾èµ–ï¼Œä½¿ç”¨æ›´ç®€å•çš„æ–¹æ³•ï¼šåœ¨èƒŒæ™¯æ¡ä¸Šæ ‡æ³¨
    frame = frame.copy()

    # ç”»åŠé€æ˜é»‘è‰²èƒŒæ™¯æ¡
    bar_h = LABEL_BAR_HEIGHT
    bar_w = min(len(text) * 10 + 8, frame.shape[1])
    alpha = 0.6
    frame[:bar_h, :bar_w] = (frame[:bar_h, :bar_w].astype(np.float32) * (1 - alpha)).astype(np.uint8)

    # ç”¨ç®€æ˜“ä½å›¾å­—ä½“æ¸²æŸ“
    _draw_bitmap_text(frame, text, x=x, y=3, color=color)

    return frame


# ç®€æ˜“ 5x7 ä½å›¾å­—ä½“ (ä»…æ•°å­— + éƒ¨åˆ†å­—ç¬¦)
_FONT_5X7 = {
    '0': ["01110", "10001", "10011", "10101", "11001", "10001", "01110"],
    '1': ["00100", "01100", "00100", "00100", "00100", "00100", "01110"],
    '2': ["01110", "10001", "00001", "00010", "00100", "01000", "11111"],
    '3': ["01110", "10001", "00001", "00110", "00001", "10001", "01110"],
    '4': ["00010", "00110", "01010", "10010", "11111", "00010", "00010"],
    '5': ["11111", "10000", "11110", "00001", "00001", "10001", "01110"],
    '6': ["00110", "01000", "10000", "11110", "10001", "10001", "01110"],
    '7': ["11111", "00001", "00010", "00100", "01000", "01000", "01000"],
    '8': ["01110", "10001", "10001", "01110", "10001", "10001", "01110"],
    '9': ["01110", "10001", "10001", "01111", "00001", "00010", "01100"],
    ' ': ["00000", "00000", "00000", "00000", "00000", "00000", "00000"],
    '/': ["00001", "00010", "00010", "00100", "01000", "01000", "10000"],
    '.': ["00000", "00000", "00000", "00000", "00000", "01100", "01100"],
    ':': ["00000", "01100", "01100", "00000", "01100", "01100", "00000"],
    'F': ["11111", "10000", "10000", "11110", "10000", "10000", "10000"],
    '#': ["01010", "01010", "11111", "01010", "11111", "01010", "01010"],
    's': ["00000", "00000", "01110", "10000", "01110", "00001", "11110"],
    '-': ["00000", "00000", "00000", "11111", "00000", "00000", "00000"],
    '_': ["00000", "00000", "00000", "00000", "00000", "00000", "11111"],
    'e': ["00000", "00000", "01110", "10001", "11111", "10000", "01110"],
    'n': ["00000", "00000", "10110", "11001", "10001", "10001", "10001"],
    'v': ["00000", "00000", "10001", "10001", "01010", "01010", "00100"],
    'l': ["01100", "00100", "00100", "00100", "00100", "00100", "01110"],
    'f': ["00110", "01000", "01000", "11100", "01000", "01000", "01000"],
    't': ["00000", "01000", "11100", "01000", "01000", "01001", "00110"],
    'r': ["00000", "00000", "10110", "11001", "10000", "10000", "10000"],
    'i': ["00100", "00000", "01100", "00100", "00100", "00100", "01110"],
    'g': ["00000", "00000", "01111", "10001", "01111", "00001", "01110"],
    'h': ["10000", "10000", "10110", "11001", "10001", "10001", "10001"],
    'w': ["00000", "00000", "10001", "10001", "10101", "10101", "01010"],
    'c': ["00000", "00000", "01110", "10000", "10000", "10001", "01110"],
    'a': ["00000", "00000", "01110", "00001", "01111", "10001", "01111"],
    'm': ["00000", "00000", "11010", "10101", "10101", "10001", "10001"],
    'p': ["00000", "00000", "11110", "10001", "11110", "10000", "10000"],
}


def _draw_bitmap_text(frame: np.ndarray, text: str, x: int, y: int,
                      color=(255, 255, 0), scale: int = 3):
    """åœ¨ numpy å›¾åƒä¸Šæ¸²æŸ“ä½å›¾æ–‡å­—ã€‚"""
    H, W = frame.shape[:2]
    cx = x
    for ch in text:
        glyph = _FONT_5X7.get(ch)
        if glyph is None:
            cx += 4 * scale  # æœªçŸ¥å­—ç¬¦è·³è¿‡
            continue
        for row_idx, row_str in enumerate(glyph):
            for col_idx, pixel in enumerate(row_str):
                if pixel == '1':
                    py = y + row_idx * scale
                    px = cx + col_idx * scale
                    # ç”» scaleÃ—scale çš„åƒç´ å—
                    y1, y2 = max(0, py), min(H, py + scale)
                    x1, x2 = max(0, px), min(W, px + scale)
                    if y1 < y2 and x1 < x2:
                        frame[y1:y2, x1:x2] = color
        cx += 6 * scale  # å­—ç¬¦é—´è·


def compose_tiled_video(
    videos: List[np.ndarray],
    labels: List[str],
    output_path: Path,
    fps: int = 30,
    gap: int = 4,
):
    """å°†å¤šä¸ªè§†é¢‘æ°´å¹³æ‹¼æ¥ä¸ºä¸€ä¸ªå¸¦æ ‡ç­¾å’Œå¸§å·çš„åˆæˆè§†é¢‘ã€‚

    Args:
        videos: æ¯ä¸ªç›¸æœºçš„å¸§æ•°ç»„åˆ—è¡¨ [N, H, W, 3]
        labels: ç›¸æœºæ ‡ç­¾åˆ—è¡¨
        output_path: è¾“å‡º MP4 è·¯å¾„
        fps: å¸§ç‡
        gap: ç›¸æœºä¹‹é—´çš„é—´éš”åƒç´ 
    """
    n_cams = len(videos)
    num_frames = min(len(v) for v in videos)
    H, W = videos[0].shape[1], videos[0].shape[2]

    # åˆæˆç”»å¸ƒå°ºå¯¸
    canvas_w = W * n_cams + gap * (n_cams - 1)
    canvas_h = H + LABEL_BAR_HEIGHT  # é¡¶éƒ¨æ ‡ç­¾æ 

    # ç¡®ä¿å°ºå¯¸ä¸ºå¶æ•° (h264 è¦æ±‚)
    canvas_w = canvas_w + (canvas_w % 2)
    canvas_h = canvas_h + (canvas_h % 2)

    output_path.parent.mkdir(parents=True, exist_ok=True)

    container = av.open(str(output_path), mode='w')
    stream = container.add_stream('h264', rate=fps)
    stream.width = canvas_w
    stream.height = canvas_h
    stream.pix_fmt = 'yuv420p'
    stream.options = {'crf': '18'}  # é«˜è´¨é‡ï¼Œæ–¹ä¾¿é€å¸§çœ‹

    print(f"\nğŸ¬ åˆæˆè§†é¢‘: {canvas_w}Ã—{canvas_h}, {num_frames} å¸§")

    for frame_idx in range(num_frames):
        # åˆ›å»ºé»‘è‰²ç”»å¸ƒ
        canvas = np.zeros((canvas_h, canvas_w, 3), dtype=np.uint8)

        # é¡¶éƒ¨å…¨å±€å¸§å·æ ‡ç­¾ (ç™½åº•é»‘å­—åŒºåŸŸ)
        canvas[:LABEL_BAR_HEIGHT, :] = 32  # æ·±ç°èƒŒæ™¯

        # ç»˜åˆ¶å…¨å±€å¸§å·
        time_s = frame_idx / fps
        global_text = f"F#{frame_idx}/{num_frames - 1} {time_s:.2f}s"
        _draw_bitmap_text(canvas, global_text, x=4, y=3, color=(255, 255, 0), scale=3)

        # æ‹¼æ¥æ¯ä¸ªç›¸æœº
        for cam_idx in range(n_cams):
            x_offset = cam_idx * (W + gap)
            f = videos[cam_idx][min(frame_idx, len(videos[cam_idx]) - 1)]

            # å†™å…¥å›¾åƒåŒºåŸŸ
            canvas[LABEL_BAR_HEIGHT:LABEL_BAR_HEIGHT + H, x_offset:x_offset + W] = f

            # åœ¨æ¯ä¸ªç›¸æœºç”»é¢å·¦ä¸Šè§’ç»˜åˆ¶ç›¸æœºå
            label = labels[cam_idx]
            _draw_bitmap_text(canvas, label,
                              x=x_offset + 4, y=LABEL_BAR_HEIGHT + 3,
                              color=(0, 255, 128), scale=2)

        # é—´éš”çº¿
        for i in range(1, n_cams):
            x_gap = i * (W + gap) - gap
            canvas[LABEL_BAR_HEIGHT:, x_gap:x_gap + gap] = 80  # ç°è‰²åˆ†éš”çº¿

        # ç¼–ç å¸§
        av_frame = av.VideoFrame.from_ndarray(canvas, format='rgb24')
        for packet in stream.encode(av_frame):
            container.mux(packet)

        # è¿›åº¦
        if (frame_idx + 1) % 500 == 0 or frame_idx == num_frames - 1:
            pct = (frame_idx + 1) / num_frames * 100
            print(f"   ç¼–ç è¿›åº¦: {frame_idx + 1}/{num_frames} ({pct:.0f}%)")

    # Flush
    for packet in stream.encode():
        container.mux(packet)
    container.close()

    file_size_mb = output_path.stat().st_size / 1024 / 1024
    print(f"\nâœ… è¾“å‡º: {output_path} ({file_size_mb:.1f} MB)")


def main():
    parser = argparse.ArgumentParser(
        description="ä¸‰ç›¸æœºè§†é¢‘å¹¶æ’åˆæˆå·¥å…· (headless å‹å¥½)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument("output_dir", type=Path, help="LeRobot v2.1 è¾“å‡ºç›®å½•")
    parser.add_argument("--episode", type=int, default=0, help="Episode ç´¢å¼• (é»˜è®¤ 0)")
    parser.add_argument("--output", type=Path, default=None,
                        help="è¾“å‡º MP4 è·¯å¾„ (é»˜è®¤: output_dir ä¸‹è‡ªåŠ¨å‘½å)")
    parser.add_argument("--fps", type=int, default=30, help="è¾“å‡ºå¸§ç‡ (é»˜è®¤ 30)")
    args = parser.parse_args()

    output_dir = args.output_dir
    episode = args.episode
    fps = args.fps

    # åˆ—å‡ºå¯ç”¨ episodes
    available = list_available_episodes(output_dir)
    if not available:
        print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {output_dir}")
        return

    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {output_dir}")
    print(f"   å¯ç”¨ episodes: {len(available)} ä¸ª, èŒƒå›´ [{available[0]}, {available[-1]}]")

    if episode not in available:
        print(f"âŒ Episode {episode} ä¸å­˜åœ¨")
        return

    # æŸ¥æ‰¾è§†é¢‘
    video_paths = find_episode_videos(output_dir, episode)
    print(f"\nğŸ“¹ åŠ è½½ episode {episode} çš„ä¸‰ä¸ªç›¸æœºè§†é¢‘...")

    # è§£ç è§†é¢‘
    videos = []
    for path, label in zip(video_paths, CAMERA_LABELS):
        print(f"   è§£ç  {label}... ", end="", flush=True)
        v = decode_video(path)
        print(f"âœ“ {v.shape[0]} å¸§, {v.shape[1]}Ã—{v.shape[2]}")
        videos.append(v)

    # éªŒè¯å¸§æ•°ä¸€è‡´
    frame_counts = [len(v) for v in videos]
    if len(set(frame_counts)) > 1:
        print(f"\nâš ï¸  å¸§æ•°ä¸ä¸€è‡´: {dict(zip(CAMERA_LABELS, frame_counts))}")
        print(f"   å°†ä½¿ç”¨æœ€å°å¸§æ•°: {min(frame_counts)}")

    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        out_path = args.output
    else:
        ep_dir = _resolve_episode_dir(output_dir, episode)
        out_path = ep_dir / f"sync_compare_ep{episode:04d}.mp4"

    # åˆæˆ
    compose_tiled_video(videos, CAMERA_LABELS, out_path, fps=fps)

    print(f"\nğŸ’¡ é€å¸§æŸ¥çœ‹æç¤º:")
    print(f"   mpv {out_path}      # æŒ‰ . ä¸‹ä¸€å¸§, , ä¸Šä¸€å¸§")
    print(f"   ffplay {out_path}   # æŒ‰ S ä¸‹ä¸€å¸§")


if __name__ == "__main__":
    main()
